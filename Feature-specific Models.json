Feature-specific Models
Currently only available in Preview.

Zed allows you to configure different models for specific features. This provides flexibility to use more powerful models for certain tasks while using faster or more efficient models for others.

If a feature-specific model is not set, it will fall back to using the default model, which is the one you set on the Agent Panel.

You can configure the following feature-specific models:

Thread summary model: Used for generating thread summaries
Inline assistant model: Used for the inline assistant feature
Commit message model: Used for generating Git commit messages
Example configuration:

{
  "assistant": {
    "version": "2",
    "default_model": {
      "provider": "zed.dev",
      "model": "claude-3-7-sonnet"
    },
    "inline_assistant_model": {
      "provider": "anthropic",
      "model": "claude-3-5-sonnet"
    },
    "commit_message_model": {
      "provider": "openai",
      "model": "gpt-4o-mini"
    },
    "thread_summary_model": {
      "provider": "google",
      "model": "gemini-2.0-flash"
    }
  }
}
Configuring Alternative Models for Inline Assists
You can configure additional models that will be used to perform inline assists in parallel. When you do this, the inline assist UI will surface controls to cycle between the alternatives generated by each model. The models you specify here are always used in addition to your default model. For example, the following configuration will generate two outputs for every assist. One with Claude 3.5 Sonnet, and one with GPT-4o.

{
  "assistant": {
    "default_model": {
      "provider": "zed.dev",
      "model": "claude-3-5-sonnet"
    },
    "inline_alternatives": [
      {
        "provider": "zed.dev",
        "model": "gpt-4o"
      }
    ],
    "version": "2"
  }
}
Common Panel Settings
key	type	default	description
enabled	boolean	true	Setting this to false will completely disable the assistant
button	boolean	true	Show the assistant icon in the status bar
dock	string	"right"	The default dock position for the assistant panel. Can be ["left", "right", "bottom"]
default_height	string	null	The pixel height of the assistant panel when docked to the bottom
default_width	string	null	The pixel width of the assistant panel when docked to the left or right
General Configuration Example
{
  "assistant": {
    "enabled": true,
    "default_model": {
      "provider": "zed.dev",
      "model": "claude-3-7-sonnet"
    },
    "editor_model": {
      "provider": "openai",
      "model": "gpt-4o"
    },
    "inline_assistant_model": {
      "provider": "anthropic",
      "model": "claude-3-5-sonnet"
    },
    "commit_message_model": {
      "provider": "openai",
      "model": "gpt-4o-mini"
    },
    "thread_summary_model": {
      "provider": "google",
      "model": "gemini-1.5-flash"
    },
    "version": "2",
    "button": true,
    "default_width": 480,
    "dock": "right"
  }
}

{
  "language_models": {
    "anthropic": {
      "available_models": [
        {
          "name": "claude-3-5-sonnet-20240620",
          "display_name": "Sonnet 2024-June",
          "max_tokens": 128000,
          "max_output_tokens": 2560,
          "cache_configuration": {
            "max_cache_anchors": 10,
            "min_total_token": 10000,
            "should_speculate": false
          },
          "tool_override": "some-model-that-supports-toolcalling"
        }
      ]
    }
  }
}
{
  "language_models": {
    "google": {
      "available_models": [
        {
          "name": "gemini-1.5-flash-latest",
          "display_name": "Gemini 1.5 Flash (Latest)",
          "max_tokens": 1000000
        }
      ]
    }
  }
}
{
  "language_models": {
    "openai": {
      "available_models": [
        {
          "name": "gpt-4o-2024-08-06",
          "display_name": "GPT 4o Summer 2024",
          "max_tokens": 128000
        },
        {
          "name": "o1-mini",
          "display_name": "o1-mini",
          "max_tokens": 128000,
          "max_completion_tokens": 20000
        }
      ]
      "version": "1"
    },
  }
}
"language_models": {
  "openai": {
    "api_url": "https://api.x.ai/v1",
    "available_models": [
      {
        "name": "grok-beta",
        "display_name": "X.ai Grok (Beta)",
        "max_tokens": 131072
      }
    ],
    "version": "1"
  },
}
// Custom endpoint
{
  "language_models": {
    "some-provider": {
      "api_url": "http://localhost:11434"
    }
  }
}
Configuring Models
The default model can be set via the model dropdown in the assistant panel's top-right corner. Selecting a model saves it as the default. You can also manually edit the default_model object in your settings:

{
  "assistant": {
    "version": "2",
    "default_model": {
      "provider": "zed.dev",
      "model": "claude-3-5-sonnet"
    }
  }
}